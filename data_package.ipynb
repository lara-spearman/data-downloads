{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe67396",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Purpose: Clip listed datasets to input area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c586668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a28a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make changes\n",
    "# What boundary are you clipping too?\n",
    "# Is it a parish council? (answer yes or no)\n",
    "parish_council = \"yes\"\n",
    "# If yes, which parish council\n",
    "boundary_name = \"Colerne\"\n",
    "\n",
    "# If no, what is the filepath to the boundary?\n",
    "boundary_area_filepath = r\"\\\\192.168.101.45\\Projects\\Data_team\\GIS_data_downloads\\CountyBoundary.shp\"\n",
    "if parish_council != \"yes\":\n",
    "    # And what is the boundary name?\n",
    "    boundary_name = \"Wiltshire\"\n",
    "\n",
    "# Do you want a buffer around the boundary? (answer yes or no)\n",
    "buffer = \"yes\"\n",
    "# If yes, what size buffer? (in metres)\n",
    "buffer_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda33969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\venvs\\data-downloads\\Lib\\site-packages\\geopandas\\geodataframe.py:1968: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "### Do not change\n",
    "# Set boundary\n",
    "if parish_council == \"yes\":\n",
    "    pc_boundaries_filepath = r\"\\\\192.168.101.45\\gis\\OS_OpenData\\OS_BoundaryLine\\OS_BL_Parish_Wilts.shp\"\n",
    "    pc_boundaries_gdf = gpd.read_file(pc_boundaries_filepath)\n",
    "    boundary_area = pc_boundaries_gdf[pc_boundaries_gdf.NAME == boundary_name]\n",
    "    # Check if boundary name valid, if not throw error\n",
    "    if boundary_area.empty == True:\n",
    "        raise ValueError(f\"Parish council name was incorrect. Full list of Parish council names: {pc_boundaries_gdf.NAME.unique()}\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        boundary_area = gpd.read_file(boundary_area_filepath)\n",
    "    except:\n",
    "        raise ValueError(\"The boundary file path was incorrect, check it is a valid file path\")\n",
    "\n",
    "\n",
    "if buffer == \"yes\":\n",
    "    boundary_area.geometry = boundary_area.geometry.buffer(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05848d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to write clipped data to\n",
    "download_location = r\"\\\\192.168.101.45\\Projects\\Data_team\\GIS_data_downloads\\dataPackage\"\n",
    "\n",
    "# Find all geopackages in folder\n",
    "dataset_area = Path(r\"\\\\192.168.101.45\\gis\\GIS_Data\\External\\Open_Source\\Original\")\n",
    "dataset_folder_list = list(dataset_area.glob(\"*/*\"))\n",
    "\n",
    "# Set date for file name\n",
    "today = date.today().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservation_Areas Conservation_Areas\n",
      "NHLE_Building_Preservation_Notices_polygons NHLE_Building_Preservation_Notices_polygons\n",
      "NHLE_Building_Preservation_Notice_points NHLE_Building_Preservation_Notice_points\n",
      "NHLE_Certificate_of_Immunity_points NHLE_Certificate_of_Immunity_points\n",
      "NHLE_Certificate_of_Immunity_polygons NHLE_Certificate_of_Immunity_polygons\n",
      "NHLE_Listed_Building_points NHLE_Listed_Building_points\n",
      "NHLE_Listed_Building_polygons NHLE_Listed_Building_polygons\n",
      "NHLE_Protected_Wreck_sites NHLE_Protected_Wreck_sites\n",
      "NHLE_Registered_Battlefields NHLE_Registered_Battlefields\n",
      "NHLE_Registered_Parks_and_Gardens NHLE_Registered_Parks_and_Gardens\n",
      "NHLE_Scheduled_Monuments NHLE_Scheduled_Monuments\n",
      "NHLE_World_Heritage_Sites NHLE_World_Heritage_Sites\n",
      "National_Trust_Open_Data_Land_Always_Open National_Trust_Open_Data_Land_Always_Open\n",
      "National_Trust_Open_Data_Land_Limited_Access National_Trust_Open_Data_Land_Limited_Access\n",
      "Access_Network_Mapping Access_Network_Mapping\n",
      "Agricultural_Land_Classification_Grades_Post_1988_Survey Agricultural_Land_Classification_Grades_Post_1988_Survey\n",
      "Ancient_Woodland Ancient_Woodland\n",
      "AONBs_National_Landscapes AONBs_National_Landscapes\n",
      "Chalk_Rivers Chalk_Rivers\n",
      "Conservation_and_Enhancement_Scheme_Agreements Conservation_and_Enhancement_Scheme_Agreements\n",
      "Countryside_Stewardship_Scheme_2016_Management_Areas Countryside_Stewardship_Scheme_2016_Management_Areas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000021DEBE99E80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Temp\\venvs\\data-downloads\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 796, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\", line 1479, in enumerate\n",
      "    def enumerate():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countryside_Stewardship_Scheme_2016_Management_Options Countryside_Stewardship_Scheme_2016_Management_Options\n",
      "Country_Parks Country_Parks\n",
      "CRoW_Act_2000_Access_Layer CRoW_Act_2000_Access_Layer\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "# Loop through each dataset folder\n",
    "for dataset_path_folder in dataset_folder_list:\n",
    "    # Get list of geopackages in folder\n",
    "    dataset_path_list = list(Path(dataset_path_folder).rglob(\"*.gpkg\"))\n",
    "    dataset_name = dataset_path_folder.stem.replace(\" \", \"_\")\n",
    "    \n",
    "    try:\n",
    "        # Check if there is a geopackage present\n",
    "        dataset_path = dataset_path_list[0]\n",
    "        filename = Path(dataset_path).stem\n",
    "    except:\n",
    "        # Skip loop if no geopackage\n",
    "        continue\n",
    "\n",
    "    # Create metadata list \n",
    "    dataset_metadata_name = dataset_path_folder.stem.replace(\"_\", \" \")\n",
    "    source_metadata = dataset_path_folder.parent.stem.replace(\"_\", \" \")\n",
    "    row_metadata = [ f\"{dataset_name}_{today}.gpkg\", dataset_metadata_name, source_metadata]\n",
    "    data_list.append(row_metadata)\n",
    "\n",
    "    # Create folder if not already there for data storage\n",
    "    if not os.path.exists(f\"{download_location}/{boundary_name}/data/\"):\n",
    "        os.makedirs(f\"{download_location}/{boundary_name}/data/\")\n",
    "\n",
    "\n",
    "\n",
    "    # List layers in geopackage\n",
    "    gpd_layers = gpd.list_layers(dataset_path)\n",
    "    # Need separate code for boundary line, as handle each layer in geopackage differently (clip or interesect)\n",
    "    if filename in [\"BoundaryLine\", \"OS_Open_Zoomstack\"]:\n",
    "        pass\n",
    "    else:\n",
    "        # Loop through each layer in file, clip to boundary and write to new location\n",
    "        count = 0\n",
    "        for i, layer in enumerate(gpd_layers.name):\n",
    "            print(filename, layer)\n",
    "            # Read in each layer of dataset\n",
    "            gdf = gpd.read_file(dataset_path, layer = layer)\n",
    "            # Clip dataset\n",
    "            gdf_clipped = gpd.clip(gdf, boundary_area)\n",
    "            # Check that geodataframe contains data\n",
    "            if gdf_clipped.empty == False:\n",
    "                # Write or append geopackage layer\n",
    "                gdf_clipped.to_file(f\"{download_location}/{boundary_name}/data/{dataset_name}_{today}.gpkg\",layer = layer, driver = \"GPKG\", mode = \"w\" if count==0 else \"a\")\n",
    "                count=+1\n",
    "# Write out metadata file\n",
    "metadata_df = pd.DataFrame(columns = [\"File name\", \"Dataset Title\", \"Source\"], data = data_list)\n",
    "metadata_df.to_csv(f\"{download_location}/{boundary_name}/File information.csv\", index = False)\n",
    "\n",
    "# Write out boundary area used\n",
    "boundary_area.to_file(f\"{download_location}/{boundary_name}/boundary_area.gpkg\", layer='boundary', driver=\"GPKG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-downloads",
   "language": "python",
   "name": "data-downloads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
