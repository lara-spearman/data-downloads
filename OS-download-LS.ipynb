{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d463d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pathlib\n",
    "from datetime import date\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0efac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set location we're working in\n",
    "location = \"work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a4fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilts_clip = {\n",
    "    \"BoundaryLine\":{\n",
    "     \"polling_districts_england\":\"intersect\",\n",
    "     \"parish\":\"intersect\",\n",
    "     \"westminster_const\":\"intersect\",\n",
    "     \"unitary_electoral_division\":\"intersect\"\n",
    "     },\n",
    "\n",
    "    \"Zoomstack\":{\n",
    "        \"airports\":\"clip\",\n",
    "    \"boundaries\":False,\n",
    "    \"contours\": \"clip\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5c2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets location to work from\n",
    "if location == \"home\":\n",
    "    folder_location = \"C:/Users/Lara/Work/DataDownloads/\"\n",
    "    \n",
    "if location == \"work\":\n",
    "    folder_location = \"O:/Data_team/GIS_data_downloads/\"\n",
    "\n",
    "download_location = \"G:/GIS_Data/External/Open_Source/\"\n",
    "temp_download_location = f\"{folder_location}testDataTemp/\"\n",
    "lookup_location = f\"{folder_location}Lookups/\"\n",
    "item_url_file = \"OS-API_URL.csv\"\n",
    "boundary_file = f\"{folder_location}CountyBoundary.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d21f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Wiltshire boundary file\n",
    "boundary_gdf = gpd.read_file(boundary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a5e513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DatasetProductName</th>\n",
       "      <th>URL</th>\n",
       "      <th>Format</th>\n",
       "      <th>Source</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OS Terrain 50</td>\n",
       "      <td>Terrain50</td>\n",
       "      <td>https://api.os.uk/downloads/v1/products/Terrai...</td>\n",
       "      <td>GeoPackage</td>\n",
       "      <td>OS</td>\n",
       "      <td>Clip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OS Open Built Up Areas</td>\n",
       "      <td>BuiltUpAreas</td>\n",
       "      <td>https://api.os.uk/downloads/v1/products/BuiltU...</td>\n",
       "      <td>GeoPackage</td>\n",
       "      <td>OS</td>\n",
       "      <td>Clip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset DatasetProductName  \\\n",
       "10           OS Terrain 50          Terrain50   \n",
       "11  OS Open Built Up Areas       BuiltUpAreas   \n",
       "\n",
       "                                                  URL      Format Source  \\\n",
       "10  https://api.os.uk/downloads/v1/products/Terrai...  GeoPackage     OS   \n",
       "11  https://api.os.uk/downloads/v1/products/BuiltU...  GeoPackage     OS   \n",
       "\n",
       "   Wiltshire  \n",
       "10      Clip  \n",
       "11      Clip  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "item_url_df = pd.read_csv(lookup_location + item_url_file)\n",
    "item_url_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c99bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of OS open data products available to download https://docs.os.uk/os-apis/accessing-os-apis/os-downloads-api/technical-specification/opendata-products\n",
    "url = 'https://api.os.uk/downloads/v1/products'\n",
    "\n",
    "response = requests.get(url)\n",
    "product_list = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948d5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_previous_spatial_files(source, dataset):\n",
    "    # Get list of spatial files downloaded for specific datatset\n",
    "    data_loc = pathlib.Path(f\"{download_location}Original/{source}/{dataset}\")\n",
    "    shp_list = list(data_loc.rglob(\"*.gpkg\"))\n",
    "\n",
    "def process_250kScaleColourRaster_wilts():\n",
    "    \"\"\"\n",
    "    Processes 250kScaleColourRaster data for wilts by selecting relevant Tiff files\n",
    "\n",
    "    Args:\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    source = \"OS\"\n",
    "    dataset = \"250kScaleColourRaster\"\n",
    "    # Data location of tif files\n",
    "    data_loc = pathlib.Path(f\"{download_location}Original/{source}/{dataset}\")\n",
    "    # Location for wilts file\n",
    "    wilts_file_location = pathlib.Path(str(data_loc).replace(\"Original\", \"Wiltshire\"))\n",
    "    # List all tif files in original location\n",
    "    tif_list = list(data_loc.rglob(\"*.tif\"))\n",
    "    # Extract only tif files which are relecant area and copy to wilts folder\n",
    "    for tif in tif_list:\n",
    "        if tif.stem in [\"SU\", \"ST\", \"SP\", \"SO\"]:\n",
    "            print(tif.stem)\n",
    "            shutil.copy(tif,wilts_file_location )\n",
    "\n",
    "def process_boundaryline_wilts(gpd_layers, file, wilts_file_location):\n",
    "    \"\"\"\n",
    "    Processes boundary line data for Wilts\n",
    "\n",
    "    Args:\n",
    "        gpd_layers (DataFrame): Layers in geopackage\n",
    "        file (str): Geospatial file to read\n",
    "        wilts_file_location (str): Output location for wilts dataset\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i, layer in enumerate(gpd_layers.name):\n",
    "        # Layers not listed in dict should not have a wiltshire version\n",
    "        if layer not in wilts_clip['BoundaryLine']:\n",
    "            continue\n",
    "        gdf = gpd.read_file(file, layer = layer)\n",
    "        if wilts_clip['BoundaryLine'][layer]== \"clip\":\n",
    "            gdf_wilts = gpd.clip(gdf, boundary_gdf)\n",
    "        elif wilts_clip['BoundaryLine'][layer]== \"intersect\":\n",
    "            target_geom = boundary_gdf.geometry.iloc[0]\n",
    "            gdf_wilts = gdf[gdf.intersects(target_geom)]\n",
    "            # gdf_wilts = gdf.intersection(boundary_gdf)\n",
    "        # Check that geodataframe contains data\n",
    "        if gdf_wilts.empty == False:\n",
    "            # Write or append geopackage layer\n",
    "            gdf_wilts.to_file(wilts_file_location,layer = layer, driver = \"GPKG\", mode = \"w\" if count==0 else \"a\")\n",
    "            count=+1\n",
    "    \n",
    "\n",
    "def process_geopackage_wilts(folder_name_wilts, source , dataset , metadata ):\n",
    "    \"\"\"\n",
    "    Processes original datasets into Wilts, geopackages only\n",
    "\n",
    "    Args:\n",
    "        folder_name_wilts (str): Output location for wilts dataset\n",
    "        source (str): Source of dataset\n",
    "        dataset (str): Dataset name\n",
    "        metadata (dict): Metadata information including version\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # Get list of spatial files downloaded for specific datatset\n",
    "    data_loc = pathlib.Path(f\"{download_location}Original/{source}/{dataset}\")\n",
    "    shp_list = list(data_loc.rglob(\"*.gpkg\"))\n",
    "    # Loop through each spatial file\n",
    "    for file in shp_list:\n",
    "        # Check folder destination exists, and if not create it\n",
    "        wilts_file_location = pathlib.Path(str(file).replace(\"Original\", \"Wiltshire\"))\n",
    "        if not os.path.exists(wilts_file_location.parent):\n",
    "            os.makedirs(wilts_file_location.parent)\n",
    "        # Remove file if it already exists as geopackage writes onto existing file\n",
    "        if os.path.exists(wilts_file_location):\n",
    "            os.remove(wilts_file_location)\n",
    "        # Loop through each layer in file, clip to wilts and write to new location\n",
    "        gpd_layers = gpd.list_layers(file)\n",
    "        # Need separate code for boundary line, as handle each layer in geopackage differently (clip or interesect)\n",
    "        if dataset == \"BoundaryLine\":\n",
    "            process_boundaryline_wilts(gpd_layers, file, wilts_file_location)\n",
    "        else:\n",
    "            count = 0\n",
    "            for i, layer in enumerate(gpd_layers.name):\n",
    "                gdf = gpd.read_file(file, layer = layer)\n",
    "                gdf_wilts = gpd.clip(gdf, boundary_gdf)\n",
    "                # Check that geodataframe contains data\n",
    "                if gdf_wilts.empty == False:\n",
    "                    # Write or append geopackage layer\n",
    "                    gdf_wilts.to_file(wilts_file_location,layer = layer, driver = \"GPKG\", mode = \"w\" if count==0 else \"a\")\n",
    "                    count=+1\n",
    "        \n",
    "        with open(folder_name_wilts+\"metadata.json\", mode=\"w\") as file:\n",
    "            json.dump(metadata,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08028b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terrain50\n",
      "[{'md5': '9d4597fcfd059253a1002388766b5c88', 'size': 161701445, 'url': 'https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=ASCII+Grid+and+GML+%28Grid%29&redirect', 'format': 'ASCII Grid and GML (Grid)', 'area': 'GB', 'fileName': 'terr50_gagg_gb.zip'}, {'md5': '03f4d4f9082a3730600f156df532d256', 'size': 1043961427, 'url': 'https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=ESRI%C2%AE+Shapefile&subformat=%28Contours%29&redirect', 'format': 'ESRIÂ® Shapefile', 'subformat': '(Contours)', 'area': 'GB', 'fileName': 'terr50_cesh_gb.zip'}, {'md5': '60fe32672499b05f912cb476307665c0', 'size': 1122162594, 'url': 'https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=GML&subformat=%28Contours%29&redirect', 'format': 'GML', 'subformat': '(Contours)', 'area': 'GB', 'fileName': 'terr50_cgml_gb.zip'}, {'md5': '670f964d3a48afc1c66758baec7ef6f5', 'size': 1229391491, 'url': 'https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=GeoPackage&redirect', 'format': 'GeoPackage', 'area': 'GB', 'fileName': 'terr50_gpkg_gb.zip'}, {'md5': '55cc09f9746d5a7ce193b292f41ba9b1', 'size': 1069100952, 'url': 'https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=Vector+Tiles&subformat=%28MBTiles%29&redirect', 'format': 'Vector Tiles', 'subformat': '(MBTiles)', 'area': 'GB', 'fileName': 'terr50_mbtiles_gb.zip'}]\n",
      "https://api.os.uk/downloads/v1/products/Terrain50/downloads?area=GB&format=GeoPackage&redirect\n",
      "Error occured for Terrain50: (\"Connection broken: ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None)\", ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None))\n",
      "BuiltUpAreas\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.os.uk', port=443): Max retries exceeded with url: /downloads/v1//products/BuiltUpAreas/downloads (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A536BF0910>: Failed to resolve 'api.os.uk' ([Errno 11004] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:977\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    976\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    978\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 11004] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x000001A536BF0910>: Failed to resolve 'api.os.uk' ([Errno 11004] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='api.os.uk', port=443): Max retries exceeded with url: /downloads/v1//products/BuiltUpAreas/downloads (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A536BF0910>: Failed to resolve 'api.os.uk' ([Errno 11004] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Product download https://docs.os.uk/os-apis/accessing-os-apis/os-downloads-api/technical-specification/download-an-opendata-product\u001b[39;00m\n\u001b[32m     10\u001b[39m url_product = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.os.uk/downloads/v1//products/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/downloads\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m response_product = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_product\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m dataset_product_list = response_product.json()\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataset_product_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\requests\\adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    674\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='api.os.uk', port=443): Max retries exceeded with url: /downloads/v1//products/BuiltUpAreas/downloads (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A536BF0910>: Failed to resolve 'api.os.uk' ([Errno 11004] getaddrinfo failed)\"))"
     ]
    }
   ],
   "source": [
    "#Loop through each dataset name in lookup\n",
    "for dataset in item_url_df.DatasetProductName.tail(2):\n",
    "    print(dataset)\n",
    "    # Get metadata for dataset\n",
    "    dataset_details_list = [d for d in product_list if d['id'] in [dataset]]\n",
    "    metadata = {\"Version\":dataset_details_list[0]['version'],\n",
    "                \"Date downloaded\":date.today().strftime('%m/%d/%Y')} \n",
    "\n",
    "    # Product download https://docs.os.uk/os-apis/accessing-os-apis/os-downloads-api/technical-specification/download-an-opendata-product\n",
    "    url_product = f\"https://api.os.uk/downloads/v1//products/{dataset}/downloads\"\n",
    "    response_product = requests.get(url_product)\n",
    "    dataset_product_list = response_product.json()\n",
    "    print(dataset_product_list)\n",
    "    # Set format required from external csv lookup (some datasets have multiple)\n",
    "    format = item_url_df[item_url_df.DatasetProductName==dataset]['Format'].item()\n",
    "    # Set source for creating folder structure\n",
    "    source = item_url_df[item_url_df.DatasetProductName==dataset]['Source'].item()\n",
    "\n",
    "    # Loop through each product in dataset list\n",
    "    for value in dataset_product_list:\n",
    "        #Only interested in specified formats/ areas\n",
    "        if value['format'] == format and value['area'] in [\"GB\"]:\n",
    "            # Set variables \n",
    "            dataset_url = value['url']\n",
    "            temp_folder_name = f\"{temp_download_location}\"\n",
    "            folder_name_original = f\"{download_location}Original/{source}/{dataset}/\"\n",
    "            folder_name_wilts = f\"{download_location}Wiltshire/{source}/{dataset}/\"\n",
    "            file_name = f\"{dataset}_{value['area']}\"\n",
    "            \n",
    "            print(dataset_url)\n",
    "            try:\n",
    "                response = requests.get(dataset_url)\n",
    "                # Check if response is successful\n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Request failed for {dataset} with status code: {response.status_code}\")\n",
    "                    break\n",
    "\n",
    "                #Create folder if not already there\n",
    "                if not os.path.exists(folder_name_original):\n",
    "                    os.makedirs(folder_name_original)\n",
    "                # # Remove file if it already exists\n",
    "                # if os.path.exists(wilts_file_location):\n",
    "                #     os.remove(wilts_file_location)\n",
    "                # Create zip file in temp location\n",
    "                with open(temp_folder_name+file_name+\".zip\", mode=\"wb\") as file:\n",
    "                    file.write(response.content)\n",
    "                # Extract zip and move to permanent location\n",
    "                with ZipFile(temp_folder_name+file_name+\".zip\", 'r') as z_object:\n",
    "                    z_object.extractall(path=folder_name_original)\n",
    "                # Write out metadata\n",
    "                with open(folder_name_original+\"metadata.json\", mode=\"w\") as file:\n",
    "                    json.dump(metadata,file)\n",
    "                \n",
    "                ## Export wiltshire data \n",
    "                # 250kScaleColourRaster\n",
    "                if dataset == \"250kScaleColourRaster\":\n",
    "                    process_250kScaleColourRaster_wilts()\n",
    "                # Geopackages which are clipped\n",
    "                if value['format'] == \"GeoPackage\":\n",
    "                    process_geopackage_wilts(folder_name_wilts, source , dataset , metadata)\n",
    "                    \n",
    "\n",
    "            except Exception as error:\n",
    "                print(f\"Error occured for {dataset}:\", error)\n",
    "                #assert \n",
    "\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-downloads",
   "language": "python",
   "name": "data-downloads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
