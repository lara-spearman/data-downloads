{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d463d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timezone, date\n",
    "from shapely.validation import make_valid\n",
    "from arcgis.geometry import Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a20331",
   "metadata": {},
   "source": [
    "Change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21816663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need updating\n",
    "location = \"work\"\n",
    "item_url_file = \"ItemURL_ArcGIS_6monthUpdates.csv\" # Replace with \"ItemURL_ArcGIS_YearlyUpdates.csv\" for yearly updates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b877e",
   "metadata": {},
   "source": [
    "Should not need updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5c2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if location == \"home\":\n",
    "    folder_location = \"C:/Users/Lara/Work/DataDownloads/\"\n",
    "    \n",
    "if location == \"work\":\n",
    "    folder_location = \"O:/Data_team/GIS_data_downloads/\"\n",
    "\n",
    "download_location = f\"G:/GIS_Data/External/Open_Source/\"\n",
    "temp_download_location = f\"{folder_location}testDataTemp/\" # check if still need this\n",
    "lookup_location = f\"{folder_location}Lookups/\"\n",
    "boundary_file = f\"{folder_location}CountyBoundary.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64eb7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiltshire boundary for creating Wilts datasets\n",
    "boundary_gdf = gpd.read_file(boundary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a5e513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Owner</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Priority Habitats Inventory (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ramsar (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sites of Special Scientific Interest (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sites of Special Scientific Interest Units (En...</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Special Areas of Conservation (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Special Protection Areas (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SSSI Impact Risk Zones (England)</td>\n",
       "      <td>NE</td>\n",
       "      <td>https://services.arcgis.com/JJzESW51TqeY9uat/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ancient Tree Inventory (ATI)</td>\n",
       "      <td>Woodland Trust</td>\n",
       "      <td>https://services-eu1.arcgis.com/WIfgdJeDbrZU1c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Dataset           Owner  \\\n",
       "2              Priority Habitats Inventory (England)              NE   \n",
       "3                                   Ramsar (England)              NE   \n",
       "4     Sites of Special Scientific Interest (England)              NE   \n",
       "5  Sites of Special Scientific Interest Units (En...              NE   \n",
       "6            Special Areas of Conservation (England)              NE   \n",
       "7                 Special Protection Areas (England)              NE   \n",
       "8                   SSSI Impact Risk Zones (England)              NE   \n",
       "9                       Ancient Tree Inventory (ATI)  Woodland Trust   \n",
       "\n",
       "                                                 URL  \n",
       "2  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "3  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "4  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "5  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "6  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "7  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "8  https://services.arcgis.com/JJzESW51TqeY9uat/a...  \n",
       "9  https://services-eu1.arcgis.com/WIfgdJeDbrZU1c...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file \n",
    "item_url_df = pd.read_csv(lookup_location + item_url_file)\n",
    "item_url_df.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf2fdfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/Ramsar_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloaded 1291 valid features.\n",
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/SSSI_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloading features 4000 → 6000 …\n",
      "Downloading features 6000 → 8000 …\n",
      "Downloaded 2128 valid features.\n",
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/SSSI_Units_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloading features 4000 → 6000 …\n",
      "Downloading features 6000 → 8000 …\n",
      "Downloading features 8000 → 10000 …\n",
      "Downloading features 10000 → 12000 …\n",
      "Downloading features 12000 → 14000 …\n",
      "Downloading features 14000 → 16000 …\n",
      "Downloading features 16000 → 18000 …\n",
      "Downloading features 18000 → 20000 …\n",
      "Downloading features 20000 → 22000 …\n",
      "Downloading features 22000 → 24000 …\n",
      "Downloading features 24000 → 26000 …\n",
      "Downloading features 26000 → 28000 …\n",
      "Downloading features 28000 → 30000 …\n",
      "Downloading features 30000 → 32000 …\n",
      "Downloaded 28305 valid features.\n",
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/Special_Areas_of_Conservation_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloaded 250 valid features.\n",
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/Special_Protection_Areas_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloaded 250 valid features.\n",
      "https://services.arcgis.com/JJzESW51TqeY9uat/arcgis/rest/services/SSSI_Impact_Risk_Zones_England/FeatureServer/0/query?\n",
      "Downloading features 0 → 2000 …\n",
      "Downloading features 2000 → 4000 …\n",
      "Downloading features 4000 → 6000 …\n",
      "Downloading features 6000 → 8000 …\n",
      "Downloading features 8000 → 10000 …\n",
      "Downloading features 10000 → 12000 …\n",
      "Downloading features 12000 → 14000 …\n",
      "Downloading features 14000 → 16000 …\n",
      "Downloading features 16000 → 18000 …\n",
      "Downloading features 18000 → 20000 …\n",
      "Downloading features 20000 → 22000 …\n",
      "Downloading features 22000 → 24000 …\n",
      "Downloading features 24000 → 26000 …\n",
      "Downloading features 26000 → 28000 …\n",
      "Downloading features 28000 → 30000 …\n",
      "Downloading features 30000 → 32000 …\n",
      "Downloading features 32000 → 34000 …\n",
      "Downloading features 34000 → 36000 …\n",
      "Downloading features 36000 → 38000 …\n",
      "Downloading features 38000 → 40000 …\n",
      "Downloading features 40000 → 42000 …\n",
      "Downloading features 42000 → 44000 …\n",
      "Downloading features 44000 → 46000 …\n",
      "Downloading features 46000 → 48000 …\n",
      "Downloading features 48000 → 50000 …\n",
      "Downloading features 50000 → 52000 …\n",
      "Downloading features 52000 → 54000 …\n",
      "Downloading features 54000 → 56000 …\n",
      "Downloading features 56000 → 58000 …\n",
      "Downloading features 58000 → 60000 …\n",
      "Downloading features 60000 → 62000 …\n",
      "Downloading features 62000 → 64000 …\n",
      "Downloading features 64000 → 66000 …\n",
      "Downloading features 66000 → 68000 …\n",
      "Downloading features 68000 → 70000 …\n",
      "Downloading features 70000 → 72000 …\n",
      "Downloading features 72000 → 74000 …\n",
      "Downloading features 74000 → 76000 …\n",
      "Downloading features 76000 → 78000 …\n",
      "Downloading features 78000 → 80000 …\n",
      "Downloading features 80000 → 82000 …\n",
      "Downloading features 82000 → 84000 …\n",
      "Downloading features 84000 → 86000 …\n",
      "Downloading features 86000 → 88000 …\n",
      "Downloading features 88000 → 90000 …\n",
      "Downloading features 90000 → 92000 …\n",
      "Downloading features 92000 → 94000 …\n",
      "Downloading features 94000 → 96000 …\n",
      "Downloading features 96000 → 98000 …\n",
      "Downloading features 98000 → 100000 …\n",
      "Downloading features 100000 → 102000 …\n",
      "Downloading features 102000 → 104000 …\n",
      "Downloading features 104000 → 106000 …\n",
      "Downloading features 106000 → 108000 …\n",
      "Downloaded 104062 valid features.\n"
     ]
    },
    {
     "ename": "DataSourceError",
     "evalue": "sqlite3_open(G:/GIS_Data/External/Open_Source/Wiltshire/NE/SSSI Impact Risk Zones (England)/SSSI Impact Risk Zones (England).gpkg) failed: unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2080\u001b[39m, in \u001b[36mpyogrio._io.ogr_create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_err.pyx:218\u001b[39m, in \u001b[36mpyogrio._err.check_pointer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m: sqlite3_open(G:/GIS_Data/External/Open_Source/Wiltshire/NE/SSSI Impact Risk Zones (England)/SSSI Impact Risk Zones (England).gpkg) failed: unable to open database file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDataSourceError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     84\u001b[39m gdf_wilts = gpd.clip(gdf, boundary_gdf)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gdf_wilts.empty == \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[43mgdf_wilts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdownload_location\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mWiltshire/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msource\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.gpkg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGPKG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Download dataset details\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\geopandas\\geodataframe.py:1637\u001b[39m, in \u001b[36mGeoDataFrame.to_file\u001b[39m\u001b[34m(self, filename, driver, schema, index, **kwargs)\u001b[39m\n\u001b[32m   1543\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[32m   1544\u001b[39m \n\u001b[32m   1545\u001b[39m \u001b[33;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1633\u001b[39m \n\u001b[32m   1634\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[32m-> \u001b[39m\u001b[32m1637\u001b[39m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\geopandas\\io\\file.py:731\u001b[39m, in \u001b[36m_to_file\u001b[39m\u001b[34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[39m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should be one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[43m_to_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    733\u001b[39m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\geopandas\\io\\file.py:793\u001b[39m, in \u001b[36m_to_file_pyogrio\u001b[39m\u001b[34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.columns.is_unique:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\pyogrio\\geopandas.py:710\u001b[39m, in \u001b[36mwrite_dataframe\u001b[39m\u001b[34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[39m\n\u001b[32m    707\u001b[39m         field_data.append(values)\n\u001b[32m    708\u001b[39m         field_mask.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\temp\\venvs\\data-downloads\\Lib\\site-packages\\pyogrio\\raw.py:723\u001b[39m, in \u001b[36mwrite\u001b[39m\u001b[34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[32m    719\u001b[39m dataset_kwargs, layer_kwargs = _preprocess_options_kwargs(\n\u001b[32m    720\u001b[39m     driver, dataset_options, layer_options, kwargs\n\u001b[32m    721\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2463\u001b[39m, in \u001b[36mpyogrio._io.ogr_write\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2282\u001b[39m, in \u001b[36mpyogrio._io.create_ogr_dataset_layer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2096\u001b[39m, in \u001b[36mpyogrio._io.ogr_create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDataSourceError\u001b[39m: sqlite3_open(G:/GIS_Data/External/Open_Source/Wiltshire/NE/SSSI Impact Risk Zones (England)/SSSI Impact Risk Zones (England).gpkg) failed: unable to open database file"
     ]
    }
   ],
   "source": [
    "#Loop through each dataset name in lookup\n",
    "for url in item_url_df.tail(7).URL:\n",
    "    print(url)\n",
    "    # Get url that contains details for dataset\n",
    "    url_details = url.replace(\"/query?\", \"?f=json\")\n",
    "    \n",
    "    # Get dataset name and source from lookup\n",
    "    dataset = item_url_df[item_url_df.URL==url]['Dataset'].item() \n",
    "    dataset = dataset.replace(\":\", \"-\")\n",
    "    source = item_url_df[item_url_df.URL==url]['Owner'].item()\n",
    "    \n",
    "    def fetch_page(offset, limit=2000):\n",
    "        \"\"\"Fetch a single page of features from ArcGIS FeatureServer.\"\"\"\n",
    "        params = {\n",
    "            \"where\": \"1=1\",\n",
    "            \"outFields\": \"*\",\n",
    "            \"returnGeometry\": \"true\",\n",
    "            \"f\": \"json\",\n",
    "            \"outSR\": 27700,  # EPSG:27700\n",
    "            \"resultOffset\": offset,\n",
    "            \"resultRecordCount\": limit\n",
    "        }\n",
    "        return requests.get(url, params=params).json()\n",
    "\n",
    "    records = []\n",
    "    geoms = []\n",
    "\n",
    "    offset = 0\n",
    "    page_size = 2000\n",
    "\n",
    "    # Keeps running while there is still data to download\n",
    "    while True:\n",
    "        print(f\"Downloading features {offset} → {offset + page_size} …\")\n",
    "        try:\n",
    "            data = fetch_page(offset, page_size)\n",
    "        except Exception as error:\n",
    "            print(f\"Request error occured for {dataset}:\", error)   \n",
    "        feats = data.get(\"features\", [])\n",
    "        if not feats:\n",
    "            break\n",
    "        # extract geom and attributes to convert json to geodataframe    \n",
    "        for feat in feats:\n",
    "            attrs = feat.get(\"attributes\", {})\n",
    "            esri_geom = feat.get(\"geometry\")\n",
    "            if not esri_geom:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                geom = Geometry(esri_geom, sr=27700).as_shapely\n",
    "                geom = make_valid(geom)  # repair invalid polygons\n",
    "                if geom.is_empty:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(\"Skipping invalid geometry:\", e)\n",
    "                continue\n",
    "\n",
    "            records.append(attrs)\n",
    "            geoms.append(geom)\n",
    "\n",
    "        offset += page_size\n",
    "\n",
    "    print(f\"Downloaded {len(records)} valid features.\")\n",
    "\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(records, geometry=geoms, crs=\"EPSG:27700\")\n",
    "\n",
    "    # Create folder if not already there for permanent data storage\n",
    "    if not os.path.exists(f\"{download_location}Original/{source}/{dataset}\"):\n",
    "        os.makedirs(f\"{download_location}Original/{source}/{dataset}\")\n",
    "    if not os.path.exists(f\"{download_location}Wiltshire/{source}/{dataset}\"):\n",
    "        os.makedirs(f\"{download_location}Wiltshire/{source}/{dataset}\")\n",
    "\n",
    "    # Remove previous file\n",
    "    if os.path.exists(f\"{download_location}Original/{source}/{dataset}/{dataset}.gpkg\"):\n",
    "        os.remove(f\"{download_location}Original/{source}/{dataset}/{dataset}.gpkg\")\n",
    "\n",
    "    # Write out original file\n",
    "    gdf.to_file(f\"{download_location}Original/{source}/{dataset}/{dataset}.gpkg\", layer=f\"{dataset}\", driver=\"GPKG\")\n",
    "    \n",
    "    # Clip to Wilts and write out\n",
    "    if os.path.exists(f\"{download_location}Wiltshire/{source}/{dataset}/{dataset}.gpkg\"):\n",
    "        os.remove(f\"{download_location}Wiltshire/{source}/{dataset}/{dataset}.gpkg\")\n",
    "    gdf_wilts = gpd.clip(gdf, boundary_gdf)\n",
    "    if gdf_wilts.empty == False:\n",
    "        gdf_wilts.to_file(f\"{download_location}Wiltshire/{source}/{dataset}/{dataset}.gpkg\",layer=f\"{dataset}\", driver=\"GPKG\")\n",
    "\n",
    "    # Download dataset details\n",
    "    try:\n",
    "        response_details = requests.get(url_details)\n",
    "        response_details.raise_for_status()\n",
    "        details = response_details.json()\n",
    "        date_last_edit = details['editingInfo']['dataLastEditDate']\n",
    "        dt = datetime.fromtimestamp(date_last_edit / 1000, tz=timezone.utc)\n",
    "        metadata = {\"Date last edited\":dt.strftime(\"%d/%m/%Y\"),\n",
    "                    \"Date downloaded\":date.today().strftime('%d/%m/%Y')} \n",
    "        with open(f\"{download_location}Original/{source}/{dataset}/metadata.json\", mode=\"w\") as file:\n",
    "            json.dump(metadata,file)\n",
    "        with open(f\"{download_location}Wiltshire/{source}/{dataset}/metadata.json\", mode=\"w\") as file:\n",
    "            json.dump(metadata,file)\n",
    "    except Exception as error:\n",
    "        print(f\"Request failed for details of {dataset}: {error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-downloads",
   "language": "python",
   "name": "data-downloads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
